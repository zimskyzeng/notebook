# 排查容器磁盘用量问题

## 一、问题表现
运维发现K8S集群某机器`/data`数据盘使用量超过85%（即`dh`命令）；但是在该node节点的`/data`路径下，使用`du`命令查看并未发现较高的磁盘占用；因此，需要定位问题原因和解决；

## 二、排查过程
1、首先尝试在node节点机器使用`du -sh *`命令检查具有真实句柄相关文件的大小；  
> 排查结论:   
> `du`命令查询的使用空间远小于`dh`命令显示的空间，因此怀疑存在进程未释放文件句柄情况；

> 说明:  
> 已被删除但仍被进程打开的文件，这些文件占用的空间不会被du统计但会被df计入。

2、通过`lsof`命令查看`deleted`相关文件信息；  
经过命令检查，看到有非常多的如下输出信息:
```
server 17266 17274      root *434u      REG             253,16  31457346  124164389 /opt/prom/log/libmatch_svr.0-47397308-01.error.5 (deleted)
server 17266 17274      root *436u      REG             253,16  31457310  124164395 /opt/prom/log/libmatch_svr.0-47397308-01.error.17 (deleted)
server 17266 17274      root *440u      REG             253,16  31457411  124164368 /opt/prom/log/libmatch_svr.0-47397308-01.log.11 (deleted)
```
> 排查结论:  
> 初步怀疑可能是PID=17266进程`server`存在进程未释放情况；

---
其实到了这里，我们已经大致分析出来了文件句柄未释放的问题，接下来进一步定位K8S文件的路径信息；

3、在node节点对PID=17266进程执行`lsof -p 17266`命令，检查文件的实际位置情况；
```
server 17266 root *542u      REG 253,16  31457442 124165427 /opt/prom/log/libmatch_svr.0-47397308-01.error.2 (deleted)
server 17266 root *543u      REG 253,16     79873 124165426 /opt/prom/log/libmatch_svr.0-47397308-01.error.2
```
> 排查结果:  
> 发现并未在node节点发现该/opt/prom/log/libmatch_svr.0-47397308-01.error.2文件路径，正常来说`lsof`命令输出的应该是node节点的绝对路径，但是这里并非如此；

> Deepseek排查原因:  
> 某些容器运行时（如 Docker/containerd）或 Kubernetes 配置可能会以特定方式挂载 /proc 文件系统：  
> ​=> ​默认情况​​：/proc/<pid>/fd/ 中的文件描述符通常显示宿主机路径。  
> => ​特殊配置​​：如果容器内挂载了 /proc 文件系统（如 --pid=host 或自定义挂载），lsof 可能读取的是容器视角的 /proc，从而显示容器内路径。

```bash
# 通过执行如下命令查看容器/proc挂载
kubectl exec -it <pod-name> -- mount | grep proc
# 得到如下输出信息，则说明容器内有挂载/proc文件系统，即有独立的/proc视图
proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)
```

> 挂载选项说明​  
> rw：可读写（但大部分 /proc 文件是只读的）。  
> nosuid：忽略 SUID 权限（安全防护）。  
> nodev：忽略设备文件（防止容器内访问宿主机设备）。  
> noexec：禁止执行 /proc 下的文件（安全防护）。  
> relatime：优化访问时间更新。  


---
此时我们知道，在第3点我们通过执行`lsof -p 17266`命令得到的路径，实际上是容器中的路径，那么我们该如何找到是哪个容器呢？实际该文件路径映射到node节点哪里呢？

4.1、通过`crictl`命令查找目标容器（推荐）
```bash
# 根据PID查询进程cgroup信息
cat /proc/PID/cgroup
# 输出信息如下
1:name=systemd:/kubepods/burstable/pod7178b647-e29d-459a-b2cf-8199e19b6e71/f8217773661197f065b8cde91262c647ff660f330340dbb968ba3ca920332654
2:pids:/kubepods/burstable/pod7178b647-e29d-459a-b2cf-8199e19b6e71/f8217773661197f065b8cde91262c647ff660f330340dbb968ba3ca920332654
```
在上述信息中，以`/`分割的最后一段开头13位即容器ID；可以使用`crictl`命令查找；
```bash
# 使用该命令获取目标容器信息
crictl ps | grep $container_id
```

4.2、通过`kubectl`和`/proc`信息直接进行关联
```bash
# 根据PID查询进程cgroup信息
cat /proc/PID/cgroup
# 输出信息如下
1:name=systemd:/kubepods/burstable/pod7178b647-e29d-459a-b2cf-8199e19b6e71/f8217773661197f065b8cde91262c647ff660f330340dbb968ba3ca920332654
2:pids:/kubepods/burstable/pod7178b647-e29d-459a-b2cf-8199e19b6e71/f8217773661197f065b8cde91262c647ff660f330340dbb968ba3ca920332654
```
```bash
# 使用该命令获取所有的容器containerID进行对比匹配
kubectl get pod --all-namespaces -o json | jq -r '.items[] | .metadata.namespace + " " + .metadata.name + " " + .status.containerStatuses[].containerID'
```

5、通过`crictl`命令+容器ID方式查找文件路径映射node节点路径
```bash
# 通过在node节点执行该命令，可以获取到容器内磁盘挂载映射的node路径
crictl inspect $container_id | jq '.info.runtimeSpec.mounts'
```
其次，我们也可以通过检查`kubelet`启动参数，检查`--root-dir`配置来定位kubelet采集的磁盘信息和挂载pod的emptydir路径；默认情况下，该路径是`/var/lib/kubelet`；

---
目前，该问题已经基本有大致处理逻辑和解决方案了；这里扩展一点，如何排查基础资源使用量多的容器Pod信息；

##  三、扩展
如何排查基础资源使用量较多的Pod信息？

方式1: 使用`kubectl top pod --all-namespaces`命令；